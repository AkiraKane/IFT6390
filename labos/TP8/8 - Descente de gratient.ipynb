{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "#Descente de gradient\n",
    "\n",
    "Aujourd'hui nous allons considérer un modèle linéaire avec deux entrées et une sortie binaire. Dans un premier temps, nous allons dériver a la main les équations de l'algorithme de la descente de gradient pour trois fonctions de cout différentes. Puis nous implémenterons deux de ces algorithmes d'apprentissage dans le cadre de la classification de la base de donnée iris.\n",
    "\n",
    "Le modèle linéaire s'écrit $f(x) = x_1 * w_1 + x_2 * w_2 + b$. Pour une étiquette $y$ ($y=0$ ou $y=1$), le cout est noté $E(f(x), y)$.\n",
    "\n",
    "Les trois fonctions de cout considerées sont les suivantes:\n",
    "\n",
    "1) $E(f(x), y) = - I_{f(x) * y < 0} f(x) * y$\n",
    "\n",
    "2) l'erreur quadratique $E(f(x), y) = \\frac{1}{2} (f(x) - y)^2$\n",
    "\n",
    "3) la cross-entropy sigmoide $E(f(x), y) = - y \\ln (sigm(f(x))) - (1-y) \\ln (1-sigm(f(x))$ ou $sigm$ est la fonction sigmoide $sigm(x) = \\frac{1}{1+e^{-x}}$.\n",
    "\n",
    "##1. Dérivations\n",
    "\n",
    "Dérivez a la main les équations de mise à jour par la descente de gradient des paramètes $w_1$, $w_2$ et $b$ pour chacun des trois couts. Que reconnaissez-vous pour le cout 1)? \n",
    "\n",
    "##2. Implémentation\n",
    "\n",
    "###Préparation des données\n",
    "\n",
    "Dans ce travail pratique on va travailler sur le dataset iris. On va utiliser seulement 2 classes: les iris avec les étiquettes 1 et 2, que l'on va transformer en 1 et 0 pour les besoins du perceptron. On va également utiliser uniquement 2 traits par iris, afin de pouvoir visualiser l'algorithme.\n",
    "\n",
    "Voici le code qui prépare les données. N'hésitez pas à regarder les *shapes* des différents sets pour voir comment les données sont préparées!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "\n",
    "#On commence par charger iris\n",
    "iris = np.loadtxt('iris.txt')\n",
    "data = iris\n",
    "\n",
    "# On se limite au cas de la classification BINAIRE donc on va seulement garder \n",
    "# données des 2 premières classes.\n",
    "# Ici on garde juste les exemples avec l'etiquette 1 et 2.\n",
    "data = data[data[:,-1]<3,:]\n",
    "# Ici on transforme chaque etiquette qui est egale a 2 en -1, pour avoir les \n",
    "# mêmes étiquettes que dans la formulation standard du perceptron (1 et -1).\n",
    "data[data[:,-1]==2,-1] = 0\n",
    "\n",
    "# On se limite à des données dont la dimension est 2, de façon à pouvoir visualiser\n",
    "# la frontière de decision avec la fonction gridplot.\n",
    "train_cols = [2,3]\n",
    "# Une variable pour contenir l'indice de la colonne correspondant aux étiquettes.\n",
    "target_ind = [data.shape[1] - 1]\n",
    "\n",
    "# Nombre de classes\n",
    "n_classes = 2\n",
    "# Nombre de points d'entrainement\n",
    "n_train = 75\n",
    "\n",
    "# Commenter pour avoir des resultats non-deterministes \n",
    "np.random.seed(2)\n",
    "\n",
    "# Déterminer au hasard des indices pour les exemples d'entrainement et de test\n",
    "inds = range(data.shape[0])\n",
    "np.random.shuffle(inds)\n",
    "train_inds = inds[:n_train]\n",
    "test_inds = inds[n_train:]\n",
    "    \n",
    "# Séparer les donnees dans les deux ensembles: entrainement et test.\n",
    "train_set = data[train_inds,:]  # garder les bonnes lignes\n",
    "train_set = train_set[:,train_cols + target_ind]  # garder les bonnes colonnes\n",
    "test_set = data[test_inds,:]\n",
    "test_set = test_set[:,train_cols + target_ind]\n",
    "\n",
    "# Normaliser les données\n",
    "mu1 = train_set[:,0].mean()\n",
    "mu2 = train_set[:,1].mean()\n",
    "sigma1 = train_set[:,0].std()\n",
    "sigma2 = train_set[:,1].std()\n",
    "train_set[:,0] -= mu1\n",
    "train_set[:,1] -= mu2\n",
    "train_set[:,0] /= sigma1\n",
    "train_set[:,1] /= sigma2\n",
    "test_set[:,0] -= mu1\n",
    "test_set[:,1] -= mu2\n",
    "test_set[:,0] /= sigma1\n",
    "test_set[:,1] /= sigma2\n",
    "\n",
    "# Sépararer l'ensemble de test: entrées et étiquettes.\n",
    "test_inputs = test_set[:,:-1]\n",
    "test_labels = test_set[:,-1]\n",
    "\n",
    "# Le taux d'apprentissage\n",
    "mu = 0.001\n",
    "\n",
    "# Le nombre max d'itérations\n",
    "max_iter = 500\n",
    "\n",
    "# La classe parente de nos modèles\n",
    "class Model:\n",
    "\n",
    "    def plot_function(self, train_data, title):\n",
    "        plt.figure()\n",
    "        d1 = train_data[train_data[:, -1] > 0]\n",
    "        d2 = train_data[train_data[:, -1] == 0]\n",
    "        plt.scatter(d1[:, 0], d1[:, 1], c='b', label='classe 1')\n",
    "        plt.scatter(d2[:, 0], d2[:, 1], c='g', label='classe 0')\n",
    "        x = np.linspace(-10, 10, 100)\n",
    "        y = -(self.weights[0]*x + self.bias)/self.weights[1]\n",
    "        plt.plot(x, y, c='r', lw=2, label='y = -(w1*x + b1)/w2')\n",
    "        plt.xlim(np.min(train_data[:, 0]) - 0.5, np.max(train_data[:, 0]) + 0.5)\n",
    "        plt.ylim(np.min(train_data[:, 1]) - 0.5, np.max(train_data[:, 1]) + 0.5)\n",
    "        plt.grid()\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title(title)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###LinearRegression et SigmoidCrossEntropy###\n",
    "\n",
    "On introduit les classes *LinearRegression* (erreur quadratique) et *SigmoidCrossEntropy* (cross-entropy sigmoid). Comme d'habitude, ce sont des algorithmes qui possèdent une fonction *train* pour entraîner l'algorithme à partir du *train_set* et une fonction *compute_prediction*, qui prédit la classe de chaque exemple de *test_inputs*.\n",
    "\n",
    "On vous demande de compléter les 2 algorithmes. Il faut compléter leur fonctions *train* avec les gradients que vous avez calculé précédemment, ainsi que leur fonctions *compute_prediction*. Nous vous laissons aussi le soin d'implémenter la boucle d'entrainement (Attention à bien utiliser *max_iter*, pour éviter que votre algorithme ne s'arrête jamais!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression(Model):\n",
    "    def __init__(self, mu, max_iter):\n",
    "        self.mu = mu\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def train(self, train_data):\n",
    "        nb_example = train_data.shape[0]\n",
    "        self.weights = np.random.randn(train_data.shape[1]-1)\n",
    "        self.bias = np.zeros(1)\n",
    "        pass\n",
    "\n",
    "    def compute_predictions(self, test_data):\n",
    "        pass\n",
    "\n",
    "\n",
    "class SigmoidCrossEntropy(Model):\n",
    "    def __init__(self, mu, max_iter):\n",
    "        self.mu = mu\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def train(self, train_data):\n",
    "        nb_example = train_data.shape[0]\n",
    "        self.weights = np.random.random(train_data.shape[1])\n",
    "        self.bias = np.zeros(1)\n",
    "        pass\n",
    "\n",
    "    def compute_predictions(self, test_data):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###Entraînement et test du modèle###\n",
    "\n",
    "Lorsqu'une des classes ci-dessus est complétée, vous peut l'entraîner et le tester!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Créer et entrainer le modele\n",
    "model = LinearRegression(mu, max_iter)\n",
    "model.train(train_set)\n",
    "model.plot_function(train_set, 'Train data')\n",
    "\n",
    "\n",
    "# Obtenir les classes prédites sur l'ensemble de test\n",
    "predictions = model.compute_predictions(test_inputs)\n",
    "\n",
    "# Convertir les sorties en classe. On prend le signe.\n",
    "classes_pred = np.sign(predictions-0.5)\n",
    "   \n",
    "# Mesurer la performance.\n",
    "err = 1.0 - np.mean(test_labels==classes_pred)\n",
    "\n",
    "model.plot_function(test_set, 'Test data')\n",
    "print \"L'erreur de test est de \", 100.0 * err,\"%\" "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
