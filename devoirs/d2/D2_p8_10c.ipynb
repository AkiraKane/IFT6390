{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import math\n",
    "import gzip, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from code.mlp import MLP\n",
    "from code.mlp_batch import MLPBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gzip,pickle\n",
    "f=gzip.open('mnist.pkl.gz')\n",
    "data=pickle.load(f, encoding='latin')\n",
    "\n",
    "\"\"\"data[0][0]: matrice de train data\n",
    "data[0][1]: vecteur des train labels\n",
    "\n",
    "data[1][0]: matrice de valid data\n",
    "data[1][0]: vecteur des valid labels\n",
    "\n",
    "data[2][0]: matrice de test data\n",
    "data[2][0]: vecteur des test labels\"\"\"\n",
    "\n",
    "train = np.matrix(data[0][0])\n",
    "valid = np.matrix(data[1][0])\n",
    "test = np.matrix(data[2][0])\n",
    "train_target = np.matrix(data[0][1]).getA1()\n",
    "valid_target = np.matrix(data[1][1]).getA1()\n",
    "test_target = np.matrix(data[2][1]).getA1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5a7d67f6fc42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnnet_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mabounassif/Documents/IFT6390/devoirs/d2/code/mlp.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train, target, lamdas, learning_rate, k, iterations, valid, valid_target, test, test_target)\u001b[0m\n\u001b[1;32m    147\u001b[0m                          \u001b[0mlamdas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_grad_w1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_grad_w2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mabounassif/miniconda3/envs/udem/lib/python3.5/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__imul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dh = train.shape[1]\n",
    "d = train.shape[1]\n",
    "m = 10\n",
    "k = 100\n",
    "epsilon = 1e-5\n",
    "\n",
    "lamdas = np.matrix([[0.0001, 0.00001],[0.0001, 0.000006]])\n",
    "learning_rate = 0.0019\n",
    "\n",
    "iterations = 500\n",
    "\n",
    "nnet = MLP(d, m, dh, epsilon, show_epoch=True)\n",
    "nnet.train(train, train_target, lamdas, learning_rate , k, iterations=iterations)\n",
    "\n",
    "nnet_batch = MLPBatch(d, m, dh, epsilon, show_epoch=True)\n",
    "nnet_batch.train(train, train_target, lamdas, learning_rate , k, iterations=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dh = train.shape[1]\n",
    "d = train.shape[1]\n",
    "m = 10\n",
    "k = 100\n",
    "epsilon = 1e-5\n",
    "\n",
    "lamdas = np.matrix([[0.0001, 0.00001],[0.0001, 0.000006]])\n",
    "learning_rate = 0.0019\n",
    "\n",
    "iterations = 500\n",
    "\n",
    "nnet_batch_9 = MLPBatch(d, m, dh, epsilon, show_epoch=True, save_datapoints=True)\n",
    "nnet_batch_9.train(train, train_target, lamdas, learning_rate , k, iterations=iterations, valid=valid, valid_target=valid_target, test=test, test_target=test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dh = train.shape[1]\n",
    "d = train.shape[1]\n",
    "m = 10\n",
    "k = 100\n",
    "epsilon = 1e-5\n",
    "\n",
    "lamdas = np.matrix([[0.0001, 0.00001],[0.0001, 0.000006]])\n",
    "learning_rate = 0.0019\n",
    "\n",
    "iterations = 7500\n",
    "\n",
    "nnet_batch_10 = MLPBatch(d, m, dh, epsilon, show_epoch=True, save_datapoints=True)\n",
    "nnet_batch_10.train(train, train_target, lamdas, learning_rate , k, iterations=iterations, valid=valid, valid_target=valid_target, test=test, test_target=test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('datapoints.json') as data_file:    \n",
    "    data = json.load(data_file)\n",
    "    \n",
    "    train_errors = data['train_error']\n",
    "    train_losses = data['train_loss']\n",
    "    \n",
    "    valid_errors = data['valid_error']\n",
    "    valid_losses = data['valid_loss']\n",
    "    \n",
    "    test_errors = data['test_error']\n",
    "    test_losses = data['test_loss']\n",
    "    \n",
    "    plt.plot(train_errors, label='train error rate')\n",
    "    plt.plot(valid_errors, label='valid error rate')\n",
    "    plt.plot(test_errors, label='test error rate')\n",
    "    plt.legend()\n",
    "    plt.title('Taux d\\'erreurs')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(train_losses, label='train loss')\n",
    "    plt.plot(valid_losses, label='valid loss')\n",
    "    plt.plot(test_losses, label='test loss')\n",
    "    plt.legend()\n",
    "    plt.title('Fonction du co√ªt')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
